---
title: "Stats 506, Fall 2018, Project"
author: "Mimi Tran, mimitran@umich.edu"
date: "11/27/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Data Analyis: Insurance 

The following packages are used in R version of the tutorial.

```{r,eval=FALSE, echo=TRUE}
# libraries--------------------------------------------------------------------
library(faraway)
library(readr)
library(dplyr)
```

# Data Preprocessing and Data Visualization

## Data Preprocessing

```{r group19_source, include=FALSE}
source('./group19.R')
# Load data--------------------------------------------------------------------
ds0 <- read_csv("insurance.csv")
names(ds0)
#have a glimpse of the data
head(ds0)
```

```{r, eval=FALSE, echo=TRUE}
# Check if is there any null---------------------------------------------------
is.na(ds0)
```

No missing value, we're good.

```{r}
# Recode: sex:femal = 1, male = 0, smoke: yes=1, no=0
ds0$sex[ds0$sex == "male"]="0"
ds0$sex[ds0$sex == "female"]="1"
ds0$smoker[ds0$smoker == "no"]="0"
ds0$smoker[ds0$smoker == "yes"]="1"
```

## Data Visualization

```{r}
# Examining the distribution of each variables---------------------------------
hist(ds0$age,xlab="Age", main="Distribution of Age")
hist(ds0$bmi,xlab="BMI", main="Distribution of BMI")
hist(ds0$children,xlab="Children", main="Distribution of Children")
hist(ds0$charges,xlab="Charges", main="Distribution of Charges")
```

```{r}
# Take log for charge since its heavy tail-------------------------------------
ds0$logcharges <- log(ds0$charges+1)
```

```{r hist_chart,message=FALSE}
hist(ds0$charges)
ds0$logcharges <- log(ds0$charges+1)
hist(ds0$logcharges, breaks = 10)
```

# Model Dignostics

Firstly, we define dependent variable y and covariates X. In this analysis, the reponse is *logcharges* and the preditors are *age*, *sex*, *bmi*, *children*, *smoker*, and *region* .

## VIF

```{r}
# Conduct the first regression!
# Since they're all smaller than 5, even smaller than 2.
fit0 <- lm(logcharges ~age+sex+bmi+children+smoker+as.factor(region), data=ds0)
X <- model.matrix(fit0)[, -1]
round(vif(X),2)
```


```{r residual_distribution}
hist(fit0$residuals, xlab="Residuals")
plot(fit0$res, xlab="Residuals")
abline(h=0) # acting like noraml so it's good.

```


## Residual plots

```{r partial_residual_plot}
plot(fit)
```

## Partial residual plots

```{r}
# Partial residual plots-------------------------------------------------------
#Which attempts to show how covariate is related to dependent variable
# if we control for the effects of all other covariates
# partial residual plots look acceptable.
fit <- lm(logcharges~ bmi, data=ds0)
plot(fit)
```

# Model Selection

For this part, we would try different adding variables and try to drop variables that are useless.
The primary concern in this case is that we have to add variables so that the residual is relatively indep with y.

### Original model

```{r}
fit0 <- lm(logcharges ~age+sex+bmi+children+smoker+as.factor(region), data=ds0)
summary(fit0)
AIC(fit0)
BIC(fit0)
```

### The first try: add interactive covariate smoker*bmi

```{r}
fit1 <-lm(logcharges ~age+sex+bmi+children+smoker+as.factor(region)+smoker*bmi, data=ds0)
summary(fit1)
BIC(fit1)
# which certainly improve the performance of the model
```

### The second try: add an interactive covariate smoker*age

```{r}
fit2 <-lm(logcharges ~age+sex+bmi+children+smoker+as.factor(region)+smoker*bmi+as.numeric(smoker)*age, data=ds0)
summary(fit2)
BIC(fit2)
# which increase the performance of the model significantly
```

Since we only have two continuous covariates, we can try to give them an extra power.

### The third try: add $bmi^{1.5}$

```{r}
 #since we only have two continuous covariates, we can try to give them an extra power, add bmi^1.5.
fit3 <-lm(logcharges ~age+sex+bmi+children+smoker+as.factor(region)+
            smoker*bmi,as.numeric(smoker)*age+bmi^1.5, data=ds0)
summary(fit3)
BIC(fit3)
```

### The fourth try: add $age^{1.5}$

```{r}
fit4 <-lm(logcharges ~age+sex+bmi+children+smoker+as.factor(region)+
            smoker*bmi,as.numeric(smoker)*age+bmi^1.5+age^1.5, data=ds0)
summary(fit4)
BIC(fit4)
```

### The fifth try: What if we take the ~~log~~ away? so we use charges instead of logcharges for the response. 
 
```{r}
fit5 <-lm(charges ~age+sex+bmi+children+smoker+as.factor(region)+
            smoker*bmi,as.numeric(smoker)*age+bmi^1.5+age^1.5, data=ds0)
summary(fit5)
BIC(fit5)
```

**Caution: this procedure is not a typical one for model selectiom. But if we take off the log, the performance certainly get better.**

Now we have added all the possible covariates we can, we can consider drop some of them. As we can see from the summary, it seems that the region parameter is not that important, so I'm only keep *northeast* in *region* column.

```{r}
new_ds0 <- ds0[which(ds0$region=="northeast"),]
#Recode: sex:femal = 1, male = 0, smoke: yes=1, no=0
new_ds0$sex[new_ds0$sex == "male"]="0"
new_ds0$sex[new_ds0$sex == "female"]="1"
new_ds0$smoker[new_ds0$smoker == "no"]="0"
new_ds0$smoker[new_ds0$smoker == "yes"]="1"
```

```{r}
# Now fit the model with only region is northeast.
fit6 <- lm(charges ~age+sex+bmi+children+smoker+smoker*bmi+
             as.numeric(smoker)*age+I(bmi^1.5)+I(age^1.5), data=new_ds0)
summary(fit6)
AIC(fit6)
BIC(fit6)
```

The AIC and BIC actually get smaller.

Similarly smoker*age is not that important either.

```{r, eval = FALSE, echo= TRUE}
fit7 <- lm(charges ~age+sex+bmi+children+smoker+smoker*bmi+region+I(bmi^1.5)+I(age^1.5),data=new_ds0)
summary(fit7)
AIC(fit7)
BIC(fit7)

```
```{r}
summary(fit7)
AIC(fit7)
BIC(fit7)
```

After dropping smoker*age, AIC and BIC values stay the same.For now, the best model would be:
charges = constant + age + sex + bmi + children + smoker + region + bmi*smoker + bmi^1.5 + age^1.5

**Caution: As you may see, the coefficient of smoker1 is negative. Please don't take the result as smoking is good for your health. Since smoke is also used in smoke:bmi, bmi is large. So the bad influence of smoking has been transferred to the smoke:bmi term.**

## Citation:

1.[link] https://github.com/yihui/knitr-examples/blob/master/023-engine-python.Rmd

2.[link] https://www.kaggle.com/sudhirnl7/linear-regrssion-tutorial





















